# Scalable Inference API

A fault-tolerant, multithreaded inference API using Spring Boot, Kafka, DLQ, and Docker â€” designed for production-grade performance and reliability.

## ğŸ”§ Tech Stack

- Java 17 + Spring Boot 3
- Apache Kafka + DLQ
- Docker + Docker Compose
- Spring Retry + KafkaListener
- Actuator for health checks

## âœ… Features

- ğŸ” Retry logic for transient failures
- ğŸ§¯ DLQ fallback for failed inferences
- âš¡ Multithreaded request handling
- ğŸ› ï¸ Clean producer/consumer architecture
- ğŸ³ Dockerized (Kafka + App)
- ğŸ“Š Observable with Spring Boot Actuator

## ğŸš€ How to Run

```bash
docker-compose up --build

## ğŸ§ª Performance

- âœ… Improved average response time by **53%** using in-memory caching and multithreaded request handling.
- Load tested using [`wrk`](https://github.com/wg/wrk) with **100 concurrent requests** over **15 seconds**, validating throughput and latency improvements under stress.
